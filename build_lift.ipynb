{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9670a9b",
   "metadata": {},
   "source": [
    "### Defining Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f303dbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = {\n",
    "    \n",
    "    'experiment_name' : 'TFIDF',\n",
    "    'collection' : 'keywords',\n",
    "    'taxonomy_type' : '',\n",
    "    'papers_type' : '_ENHANCED'\n",
    "}\n",
    "keywords = (experiment['collection'] == 'keywords')\n",
    "shortcut = {'_ENHANCED':'enh', '':'std'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6a4f0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs import *\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "\n",
    "EXP_DIR = f\"experiments/{experiment['experiment_name']}/{experiment['collection']}\"\n",
    "makedir(EXP_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca7faee",
   "metadata": {},
   "source": [
    "### Loading Relevance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "562d2fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rel_mat = load_obj(\n",
    "#     f'input_data/relevance_matrices/{experiment[\"experiment_name\"]}\\\n",
    "# /rel_mat_{experiment[\"experiment_name\"]}\\\n",
    "# _{\"keywords_\" if keywords else \"\"}\\\n",
    "# {shortcut[experiment[\"papers_type\"]]}_{shortcut[experiment[\"taxonomy_type\"]]}.pkl'\n",
    "# )\n",
    "\n",
    "topics_unique = load_obj(name=\n",
    "                    f'input_data/taxonomies/unique_topics{experiment[\"taxonomy_type\"]}'\n",
    "                           )\n",
    "\n",
    "indices_unique = load_obj(name=\n",
    "                          f\"input_data/taxonomies/unique_indices{experiment['taxonomy_type']}\")\n",
    "\n",
    "papers_df = pd.read_csv(f'input_data/text_collections/papers_df{experiment[\"papers_type\"]}.csv',\n",
    "                            index_col=0)\n",
    "\n",
    "if keywords:\n",
    "    papers_df['keywords'] = papers_df['keywords'].apply(eval)\n",
    "    texts = papers_df['keywords'].apply(lambda x: ' '.join(x)).str.lower().to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7b8b0e",
   "metadata": {},
   "source": [
    "### Building Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a05a630a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUILDING TEXT2TOKEN RELEVANCE MATRIX\n",
      "AGGREGATING TEXT2TOKEN --> TEXT2TOPIC (MAIN RELEVANCE MATRIX)\n"
     ]
    }
   ],
   "source": [
    "# sim_mat = load_obj(name=f'input_data/similarity_matrices/{experiment[\"experiment_name\"]}/'+\n",
    "# f'sim_mat_{experiment[\"experiment_name\"]}_{\"keywords_\" if keywords else \"\"}' + \n",
    "# f'{shortcut[experiment[\"papers_type\"]]}_{shortcut[experiment[\"taxonomy_type\"]]}.pkl'\n",
    "\n",
    "# )\n",
    "\n",
    "def diag_mult(v, M):\n",
    "    result = M.copy()\n",
    "    for i in range(M.shape[0]):\n",
    "        result[i] = v[i]*result[i]    \n",
    "    return result\n",
    "\n",
    "import custom\n",
    "sim_model = custom.TFIDF(aggregation_F='max', verbose=True)\n",
    "sim_model.fit(texts, topics_unique)\n",
    "rel_mat = sim_model.rel_mat\n",
    "text_pop = rel_mat.sum(axis=1)\n",
    "rel_mat = rel_mat[(text_pop>0.5)&(text_pop<15), :]\n",
    "text_pop = rel_mat.sum(axis=1)\n",
    "\n",
    "\n",
    "inv_pop = 1/text_pop\n",
    "sim_mat = rel_mat.T@diag_mult(inv_pop, rel_mat)\n",
    "sim_mat = rel_mat.T@rel_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b45d328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "l, V = np.linalg.eigh(sim_mat)\n",
    "\n",
    "idx = np.argsort(V[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4598c5b6",
   "metadata": {},
   "source": [
    "### Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17e46d44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<LaplacianFCM.LaplacianFCM at 0x125e61760>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.manifold import spectral_embedding\n",
    "from sklearn.cluster import KMeans\n",
    "from fcmeans import FCM\n",
    "from LaplacianFCM import LaplacianFCM\n",
    "from sklearn.decomposition import PCA\n",
    "import utils\n",
    "\n",
    "clf = LaplacianFCM(n_clusters=12, embedding_dim=12, random_state=1)\n",
    "\n",
    "clf.fit(sim_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ba2d347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils \n",
    "reload(utils)\n",
    "from utils import Clusters\n",
    "\n",
    "cl_fcm = Clusters(clf.fcm.u.copy(), topics_unique, clf.embedding, random_state=1)\n",
    "cl_km = Clusters(clf.kmeans.u.copy(), topics_unique, clf.embedding, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16b489e",
   "metadata": {},
   "source": [
    "### Lifting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pargenfs",
   "language": "python",
   "name": "pargenfs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
