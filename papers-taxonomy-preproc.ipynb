{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed to preprocess the text collection of abstracts and the taxonomy of Data Science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs import *\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N abstracts :: 17685\n",
      "N abstracts with more then 100 symbols :: 17668\n"
     ]
    }
   ],
   "source": [
    "abstracts = []\n",
    "abstracts_path = 'input_data/text_collections/Springer_abstracts'\n",
    "MIN_SYMBOLS = 100  # the min necessary amount of characters in the abstract\n",
    "for file_name in os.listdir(abstracts_path):\n",
    "    with open(os.path.join(abstracts_path, file_name), 'r') as f:\n",
    "        f_abstract = ' '.join(f.readlines()).replace('Abstract ', '')\n",
    "        \n",
    "        if len(f_abstract) > MIN_SYMBOLS:\n",
    "            abstracts.append(f_abstract)\n",
    "papers_df = pd.DataFrame(abstracts, columns=['abstract']) \n",
    "\n",
    "print(f'N abstracts :: {len(os.listdir(abstracts_path))}')\n",
    "print(f'N abstracts with more then {MIN_SYMBOLS} symbols :: {len(abstracts)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving proccesed papers\n",
    "papers_df.to_csv('input_data/text_collections/papers_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In this paper, we propose an innovative end-to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Some forms of mild cognitive impairment (MCI) ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract\n",
       "0  In this paper, we propose an innovative end-to...\n",
       "1  Some forms of mild cognitive impairment (MCI) ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enhanced abstracts preprocessing (new scrapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts_path = 'input_data/text_collections/springer_papers_ENHANCED.json'\n",
    "with open(abstracts_path, 'r') as f:\n",
    "    papers_list_raw = json.load(f)\n",
    "papers_list = []\n",
    "for paper in papers_list_raw:\n",
    "    if len(paper['abstract']) > MIN_SYMBOLS:\n",
    "        papers_list.append(paper)\n",
    "papers_df_enh = pd.DataFrame(papers_list)  # enh for enhanced\n",
    "\n",
    "papers_df_enh = (\n",
    "    papers_df_enh.assign(\n",
    "        datetime = lambda x: pd.to_datetime(x['datetime']),\n",
    "        # to ASCII\n",
    "        abstract = lambda x: x['abstract']\n",
    "                    .str.replace(r'[^\\x00-\\x7F]+', ' ', regex=True)  # to ASCII\n",
    "                    .str.replace('\\\\\\\\\\(.*\\)', '', regex=True),  # delete LATEX\n",
    "        title = lambda x: x['title'].str.replace(r'[^\\x00-\\x7F]+', ' ', regex=True),\n",
    "\n",
    "        keywords = lambda x: x['keywords']\n",
    "                    # to ASCII\n",
    "                    .apply(lambda k_list: [re.sub(r'[^\\x00-\\x7F]+','', k) for k in k_list])\n",
    "\n",
    "\n",
    "                    # deleting strange new_line characters\n",
    "                    .apply(lambda k_list: [re.sub(r'\\n','', k) for k in k_list])\n",
    "\n",
    "\n",
    "                    # dealing with parenthesis exp.\n",
    "                    .apply(lambda k_list: [re.sub(r'\\(,\\)','', k) for k in k_list])\n",
    "                    .apply(lambda k_list: [re.sub(r'\\(,*\\s*','(', k) for k in k_list])\n",
    "                    .apply(lambda k_list: [re.sub(r'^\\)\\s*','', k) for k in k_list])\n",
    "\n",
    "                    .apply(lambda k_list: [re.sub(r', \\)',r')', k) for k in k_list])\n",
    "                        # deleting latex expressions (or other typesetting)\n",
    "                    .apply(lambda k_list: [re.sub('\\\\\\\\\\(.*\\)', '', k) for k in k_list])\n",
    "                        # deleting empty parenthesis \n",
    "                    .apply(lambda k_list: [re.sub(r'\\(\\s*\\)','', k) for k in k_list])\n",
    "\n",
    "\n",
    "\n",
    "                    # deleting strange digit keywords (except for 3D, 5G)\n",
    "                    .apply(lambda k_list: [re.sub(r'\\d[^dDGg].*','', k) for k in k_list])\n",
    "\n",
    "\n",
    "                    # start\n",
    "                    .apply(lambda k_list: [re.sub(r'^-','', k) for k in k_list])\n",
    "                    .apply(lambda k_list: [re.sub(r'^#.*','', k) for k in k_list])\n",
    "                    .apply(lambda k_list: [re.sub(r'^\\s*','', k) for k in k_list])\n",
    "                    .apply(lambda k_list: [re.sub(r'^\\*-','', k) for k in k_list])\n",
    "                    .apply(lambda k_list: [re.sub(r'^-','', k) for k in k_list])\n",
    "\n",
    "                    # stripping\n",
    "                    .apply(lambda k_list: [k.strip() for k in k_list])\n",
    "\n",
    "\n",
    "                    # deleting short\n",
    "                    .apply(lambda k_list: [k for k in k_list if len(k) > 3])\n",
    "    \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving proccesed papers\n",
    "papers_df_enh.to_csv('input_data/text_collections/papers_df_ENHANCED.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_words = []\n",
    "for paper_key_words in papers_df_enh['keywords'].to_list():\n",
    "    for key_w in paper_key_words:\n",
    "        key_words.append(key_w)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for key_w in key_words:\n",
    "    for w in key_w.split():\n",
    "        words.append(\n",
    "            w.strip()\n",
    "            .strip('-').strip()\n",
    "            .strip('(').strip(')').strip()\n",
    "            .lower()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing DS taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_raw = pd.read_csv('input_data/taxonomies/acm_ccs_taxonomy_reduced_raw.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Theory of computation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Theory and algorithms for application domains</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0                      1                                              2   \\\n",
       "0     1  Theory of computation                                            NaN   \n",
       "1  1.1.                    NaN  Theory and algorithms for application domains   \n",
       "\n",
       "    3    4    5    6   7   8   9    10  \n",
       "0  NaN  NaN  NaN  NaN NaN NaN NaN  NaN  \n",
       "1  NaN  NaN  NaN  NaN NaN NaN NaN  NaN  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxonomy_raw.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_taxonomy(taxonomy_raw):\n",
    "    taxonomy_df = (\n",
    "    taxonomy_raw\n",
    "    .fillna('')\n",
    "    .assign(\n",
    "        label = lambda x: x.iloc[:, 1:].sum(1).str.strip()\n",
    "                                              .str.replace('(', '')\n",
    "                                              .str.replace(')', '')\n",
    "                                              .str.replace(',', '')\n",
    "                                              .str.replace('/', '')\n",
    "                                              .str.replace('  ', ' ')\n",
    "\n",
    "        \n",
    "        ,  # extracting nodes labels\n",
    "        new=lambda x: x[0].str.contains('\\*'),  # indicating new nodes\n",
    "        level = lambda x: x[0]\n",
    "                            .str.replace('\\s*\\+\\s*0', '', regex=True)\n",
    "                            .str.replace('\\*+', '', regex=True)  # extracting nodes indexes\n",
    "                            .str.replace(r'\\.$', '', regex=True)                       \n",
    "        ,\n",
    "        lvls = lambda x: x['level'].str.split('.'), # nodes indexes as lists\n",
    "        depth = lambda x: x['lvls'].apply(len)  # extracting depth of nodes\n",
    "    )\n",
    "    .loc[:, ['level', 'label', 'depth', 'lvls', 'new']]  # reordering in convenient way\n",
    ")\n",
    "    return taxonomy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N nodes in taxonomy :: 417\n",
      "    5 on level 1\n",
      "    9 on level 2\n",
      "   39 on level 3\n",
      "  196 on level 4\n",
      "  157 on level 5\n",
      "   11 on level 6\n"
     ]
    }
   ],
   "source": [
    "taxonomy_df = preprocess_taxonomy(taxonomy_raw)\n",
    "\n",
    "\n",
    "# changing wrong idx 2.1.2.5.1 --> 2.1.2.5\n",
    "taxonomy_df.loc[58, 'level'] = '2.1.2.5'\n",
    "taxonomy_df.loc[58, 'depth']  = 4\n",
    "\n",
    "# typos\n",
    "idx = taxonomy_df[taxonomy_df['label']=='Supervised dimesionality reduction'].index\n",
    "taxonomy_df.at[idx, 'label'] = 'Supervised dimensionality reduction'\n",
    "idx = taxonomy_df[taxonomy_df['label']=='Modelling'].index\n",
    "taxonomy_df.at[idx, 'label'] = 'Modeling'\n",
    "idx = taxonomy_df[taxonomy_df['label']=='Rule-based netwok archirtecture'].index\n",
    "taxonomy_df.at[idx, 'label'] = 'Rule-based network architecture'\n",
    "\n",
    "\n",
    "\n",
    "# printing taxonomy description\n",
    "print(f'N nodes in taxonomy :: {len(taxonomy_df)}')\n",
    "for depth in range(taxonomy_df.depth.min(), taxonomy_df.depth.max() + 1 ):\n",
    "    print(f'{(taxonomy_df.depth==depth).sum() : >5} on level {depth}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enhanced taxonomy preprocessing (new scrapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_raw_enh = pd.read_csv('input_data/taxonomies/acm_css_taxonomy_ENHANCED_raw.csv', header=None)\n",
    "taxonomy_raw_enh.drop(axis=0, index=len(taxonomy_raw_enh)-1, inplace=True)  # dropping last dummy row\n",
    "taxonomy_raw_enh.dropna(axis=0, how='all', inplace=True)  # dropping empty rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N nodes in taxonomy :: 456\n",
      "    6 on level 1\n",
      "    9 on level 2\n",
      "   39 on level 3\n",
      "  220 on level 4\n",
      "  171 on level 5\n",
      "   11 on level 6\n"
     ]
    }
   ],
   "source": [
    "taxonomy_df_enh = preprocess_taxonomy(taxonomy_raw_enh)\n",
    "\n",
    "idx = taxonomy_df_enh[taxonomy_df_enh['level']=='s'].index\n",
    "taxonomy_df_enh.at[idx, 'level'] = '1.1.5.9'\n",
    "\n",
    "# printing taxonomy description\n",
    "print(f'N nodes in taxonomy :: {len(taxonomy_df_enh)}')\n",
    "for depth in range(taxonomy_df_enh.depth.min(), taxonomy_df_enh.depth.max() + 1 ):\n",
    "    print(f'{(taxonomy_df_enh.depth==depth).sum() : >5} on level {depth}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AnyTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_AnyTree_tree(taxonomy_df):\n",
    "    # building anytree object for taxonomy\n",
    "    '''\n",
    "    This processing works under assumption that nodes are given in DFS order\n",
    "    '''\n",
    "\n",
    "    root = anytree.Node('root', raw_name='root')\n",
    "    nodes = [root]\n",
    "    prev_depth = 0\n",
    "    parent = root\n",
    "    for _, s in taxonomy_df.iterrows():\n",
    "        curr_depth = s['depth']\n",
    "        if curr_depth < prev_depth:\n",
    "            # lift parent\n",
    "            for _ in range(prev_depth - curr_depth):\n",
    "                parent = parent.parent\n",
    "        elif curr_depth == prev_depth:\n",
    "            # parent does not change\n",
    "            pass\n",
    "        elif curr_depth == prev_depth + 1:\n",
    "            # parent is the previous node\n",
    "            parent = nodes[-1]\n",
    "        else:  # if curr_depth > prev_depth + 1\n",
    "            print(s)\n",
    "            raise RuntimeError('Input nodes are not in DFS order. Please sort them in DFS order.')\n",
    "\n",
    "        n = anytree.Node(f\"{s['level']} -- {s['label']}\", raw_name=s['label'], parent=parent)\n",
    "        nodes.append(n)\n",
    "        prev_depth = curr_depth\n",
    "    \n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = build_AnyTree_tree(taxonomy_df)\n",
    "\n",
    "leaves = [i.raw_name for i in anytree.LevelOrderIter(root, filter_=lambda x: x.is_leaf)]\n",
    "print(f'Number of leaves in Taxonomy: {len((leaves))}')\n",
    "\n",
    "taxonomy_df['is_leaf'] = taxonomy_df['label'].isin(leaves) # adding leaf indicator\n",
    "\n",
    "taxonomy_df.to_csv('input_data/taxonomies/taxonomy_df.csv')  # saving taxonomy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of leaves in Taxonomy Enhanced: 352\n"
     ]
    }
   ],
   "source": [
    "root_enh = build_AnyTree_tree(taxonomy_df_enh)\n",
    "\n",
    "leaves_enh = [i.raw_name for i in anytree.LevelOrderIter(root_enh, filter_=lambda x: x.is_leaf)]\n",
    "print(f'Number of leaves in Taxonomy Enhanced: {len((leaves_enh))}')\n",
    "\n",
    "taxonomy_df_enh['is_leaf'] = taxonomy_df['label'].isin(leaves_enh) # adding leaf indicator\n",
    "\n",
    "taxonomy_df_enh.to_csv('input_data/taxonomies/taxonomy_df_ENHANCED.csv')  # saving taxonomy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N of duplicate pairs :: 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>label</th>\n",
       "      <th>depth</th>\n",
       "      <th>lvls</th>\n",
       "      <th>new</th>\n",
       "      <th>is_leaf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>5.2.3.7.3.1</td>\n",
       "      <td>2D PCA</td>\n",
       "      <td>6</td>\n",
       "      <td>[5, 2, 3, 7, 3, 1]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>5.1.3.2.1.1</td>\n",
       "      <td>2D PCA</td>\n",
       "      <td>6</td>\n",
       "      <td>[5, 1, 3, 2, 1, 1]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.1.1.13.5</td>\n",
       "      <td>Adversarial learning</td>\n",
       "      <td>5</td>\n",
       "      <td>[1, 1, 1, 13, 5]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>5.2.1.3.5</td>\n",
       "      <td>Adversarial learning</td>\n",
       "      <td>5</td>\n",
       "      <td>[5, 2, 1, 3, 5]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           level                 label  depth                lvls    new  \\\n",
       "383  5.2.3.7.3.1                2D PCA      6  [5, 2, 3, 7, 3, 1]   True   \n",
       "308  5.1.3.2.1.1                2D PCA      6  [5, 1, 3, 2, 1, 1]   True   \n",
       "23    1.1.1.13.5  Adversarial learning      5    [1, 1, 1, 13, 5]  False   \n",
       "334    5.2.1.3.5  Adversarial learning      5     [5, 2, 1, 3, 5]  False   \n",
       "\n",
       "     is_leaf  \n",
       "383     True  \n",
       "308     True  \n",
       "23      True  \n",
       "334     True  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# repeating names\n",
    "unique_names=set()\n",
    "duplicate_names=set()\n",
    "for _, s in taxonomy_df.iterrows():\n",
    "    name = s['label']\n",
    "    if name in unique_names:\n",
    "        duplicate_names.add(name)\n",
    "    else:\n",
    "        unique_names.add(name)\n",
    "\n",
    "print(f'N of duplicate pairs :: {len(duplicate_names)}')\n",
    "duplicate_mask = taxonomy_df['label'].isin(duplicate_names)  \n",
    "\n",
    "taxonomy_df[duplicate_mask].sort_values(by='label').head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N of duplicate pairs :: 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>label</th>\n",
       "      <th>depth</th>\n",
       "      <th>lvls</th>\n",
       "      <th>new</th>\n",
       "      <th>is_leaf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>5.2.3.7.3.1</td>\n",
       "      <td>2D PCA</td>\n",
       "      <td>6</td>\n",
       "      <td>[5, 2, 3, 7, 3, 1]</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>5.1.3.2.1.1</td>\n",
       "      <td>2D PCA</td>\n",
       "      <td>6</td>\n",
       "      <td>[5, 1, 3, 2, 1, 1]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>5.2.1.3.5</td>\n",
       "      <td>Adversarial learning</td>\n",
       "      <td>5</td>\n",
       "      <td>[5, 2, 1, 3, 5]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.1.1.13.5</td>\n",
       "      <td>Adversarial learning</td>\n",
       "      <td>5</td>\n",
       "      <td>[1, 1, 1, 13, 5]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           level                 label  depth                lvls    new  \\\n",
       "422  5.2.3.7.3.1                2D PCA      6  [5, 2, 3, 7, 3, 1]   True   \n",
       "340  5.1.3.2.1.1                2D PCA      6  [5, 1, 3, 2, 1, 1]   True   \n",
       "368    5.2.1.3.5  Adversarial learning      5     [5, 2, 1, 3, 5]  False   \n",
       "23    1.1.1.13.5  Adversarial learning      5    [1, 1, 1, 13, 5]  False   \n",
       "\n",
       "    is_leaf  \n",
       "422     NaN  \n",
       "340    True  \n",
       "368    True  \n",
       "23     True  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# repeating names\n",
    "unique_names=set()\n",
    "duplicate_names=set()\n",
    "for _, s in taxonomy_df_enh.iterrows():\n",
    "    name = s['label']\n",
    "    if name in unique_names:\n",
    "        duplicate_names.add(name)\n",
    "    else:\n",
    "        unique_names.add(name)\n",
    "\n",
    "print(f'N of duplicate pairs :: {len(duplicate_names)}')\n",
    "duplicate_mask = taxonomy_df_enh['label'].isin(duplicate_names)  \n",
    "\n",
    "taxonomy_df_enh[duplicate_mask].sort_values(by='label').head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising Taxonomy Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for requesting nodes path\n",
    "\n",
    "def get_node_path(index, root):\n",
    "    '''\n",
    "    input: node index as a string \n",
    "    output: path from root to node as a string\n",
    "    '''\n",
    "    def get_full_name(node):\n",
    "        '''\n",
    "        input: node as an anytree object\n",
    "        output: path from root to node as a string\n",
    "        '''\n",
    "        ancestors = node.ancestors\n",
    "        name = '/'\n",
    "        for anc in ancestors:\n",
    "            name+=anc.name+'/'\n",
    "        return name + node.name + '/'\n",
    "    \n",
    "    index = list(map(int, index.split('.')))\n",
    "    index = np.array(index) - 1  # indexation in anytree starts from 0 not 1\n",
    "\n",
    "    node = root\n",
    "    for idx in index:\n",
    "        node = node.children[idx]\n",
    "        \n",
    "    return get_full_name(node)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from anytree import Resolver\n",
    "from anytree.exporter import DotExporter\n",
    "# node = Resolver().get(root, '/root/1 -- Theory of computation/1.1 -- Theory and algorithms for application domains/1.1.1 -- Machine learning theory')\n",
    "# node = Resolver().get(root, '/root')\n",
    "index = '3.2.1.4'  # index of node clustering\n",
    "node = Resolver().get(root, get_node_path(index, root))\n",
    "\n",
    "\n",
    "dot = DotExporter(node)\n",
    "dot.to_dotfile(f'visualization/taxonomies/sub_tax_clustering.dot')\n",
    "!dot -Tpdf visualization/taxonomies/sub_tax_clustering.dot -o visualization/taxonomies/sub_tax_clustering.pdf  # creating pdf \n",
    "!rm visualization/taxonomies/sub_tax_clustering.dot  # deleting dot file from directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Writing <u>toy taxonomy </u> file for visual convenience.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_taxonomy_txt(root, fpath):\n",
    "    # print in DFS order\n",
    "    f = open(fpath, 'w')\n",
    "    for pre, fill, node in anytree.RenderTree(root):\n",
    "        f.write(f'{pre}{node.name}\\n')\n",
    "        print(pre, node.name, sep='')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      "├── 1 -- Theory of computation\n",
      "│   └── 1.1 -- Theory and algorithms for application domains\n",
      "│       ├── 1.1.1 -- Machine learning theory\n",
      "│       │   ├── 1.1.1.1 -- Sample complexity and generalization bounds\n",
      "│       │   ├── 1.1.1.2 -- Boolean function learning\n",
      "│       │   ├── 1.1.1.3 -- Unsupervised learning and clustering\n",
      "│       │   ├── 1.1.1.4 -- Kernel methods\n",
      "│       │   │   ├── 1.1.1.4.1 -- Support vector machines\n",
      "│       │   │   ├── 1.1.1.4.2 -- Gaussian processes\n",
      "│       │   │   └── 1.1.1.4.3 -- Modelling\n",
      "│       │   ├── 1.1.1.5 -- Boosting\n",
      "│       │   ├── 1.1.1.6 -- Bayesian analysis\n",
      "│       │   ├── 1.1.1.7 -- Inductive inference\n",
      "│       │   ├── 1.1.1.8 -- Online learning theory\n",
      "│       │   ├── 1.1.1.9 -- Multi-agent learning\n",
      "│       │   ├── 1.1.1.10 -- Models of learning\n",
      "│       │   ├── 1.1.1.11 -- Query learning\n",
      "│       │   ├── 1.1.1.12 -- Structured prediction\n",
      "│       │   ├── 1.1.1.13 -- Reinforcement learning\n",
      "│       │   │   ├── 1.1.1.13.1 -- Sequential decision making\n",
      "│       │   │   ├── 1.1.1.13.2 -- Inverse reinforcement learning\n",
      "│       │   │   ├── 1.1.1.13.3 -- Apprenticeship learning\n",
      "│       │   │   ├── 1.1.1.13.4 -- Multi-agent reinforcement learning\n",
      "│       │   │   └── 1.1.1.13.5 -- Adversarial learning\n",
      "│       │   ├── 1.1.1.14 -- Active learning\n",
      "│       │   ├── 1.1.1.15 -- Semi-supervised learning\n",
      "│       │   ├── 1.1.1.16 -- Markov decision processes\n",
      "│       │   └── 1.1.1.17 -- Regret bounds\n",
      "│       └── 1.1.2 -- Database theory\n",
      "│           ├── 1.1.2.1 -- Data exchange\n",
      "│           ├── 1.1.2.2 -- Data provenance\n",
      "│           ├── 1.1.2.3 -- Data modeling\n",
      "│           ├── 1.1.2.4 -- Database query languages principles\n",
      "│           ├── 1.1.2.5 -- Database constraints theory\n",
      "│           ├── 1.1.2.6 -- Database interoperability\n",
      "│           ├── 1.1.2.7 -- Data structures and algorithms for data management\n",
      "│           ├── 1.1.2.8 -- Database query processing and optimization theory\n",
      "│           ├── 1.1.2.9 -- Data integration\n",
      "│           ├── 1.1.2.10 -- Logic and databases\n",
      "│           ├── 1.1.2.11 -- Theory of database privacy and security\n",
      "│           └── 1.1.2.12 -- Incomplete inconsistent and uncertain databases\n",
      "├── 2 -- Mathematics of computing\n",
      "│   └── 2.1 -- Probability and statistics\n",
      "│       ├── 2.1.1 -- Probabilistic representations\n",
      "│       │   ├── 2.1.1.1 -- Bayesian networks\n",
      "│       │   ├── 2.1.1.2 -- Markov networks\n",
      "│       │   ├── 2.1.1.3 -- Factor graphs\n",
      "│       │   ├── 2.1.1.4 -- Decision diagrams\n",
      "│       │   ├── 2.1.1.5 -- Equational models\n",
      "│       │   ├── 2.1.1.6 -- Causal networksACM-1\n",
      "│       │   ├── 2.1.1.7 -- Stochastic differential equations\n",
      "│       │   └── 2.1.1.8 -- Nonparametric representations\n",
      "│       │       ├── 2.1.1.8.1 -- Kernel density estimators\n",
      "│       │       ├── 2.1.1.8.2 -- Spline models\n",
      "│       │       └── 2.1.1.8.3 -- Bayesian nonparametric models\n",
      "│       ├── 2.1.2 -- Probabilistic inference problems\n",
      "│       │   ├── 2.1.2.1 -- Maximum likelihood estimation\n",
      "│       │   ├── 2.1.2.2 -- Bayesian computation\n",
      "│       │   ├── 2.1.2.5 -- Quantile regression\n",
      "│       │   └── 2.1.2.6 -- Max marginal computation\n",
      "│       ├── 2.1.3 -- Probabilistic reasoning algorithms\n",
      "│       │   ├── 2.1.3.1 -- Variable elimination\n",
      "│       │   ├── 2.1.3.2 -- Loopy belief propagation\n",
      "│       │   ├── 2.1.3.3 -- Variational methods\n",
      "│       │   ├── 2.1.3.4 -- Expectation maximization\n",
      "│       │   ├── 2.1.3.5 -- Markov-chain Monte Carlo methods\n",
      "│       │   │   ├── 2.1.3.5.1 -- Gibbs sampling\n",
      "│       │   │   ├── 2.1.3.5.2 -- Metropolis-Hastings algorithm\n",
      "│       │   │   ├── 2.1.3.5.3 -- Simulated annealing\n",
      "│       │   │   └── 2.1.3.5.4 -- Markov-chain Monte Carlo convergence measures\n",
      "│       │   ├── 2.1.3.6 -- Sequential Monte Carlo methods\n",
      "│       │   ├── 2.1.3.7 -- Kalman filters and hidden Markov models\n",
      "│       │   │   └── 2.1.3.7.1 -- Factorial HMM\n",
      "│       │   ├── 2.1.3.8 -- Resampling methods\n",
      "│       │   │   ├── 2.1.3.8.1 -- Bootstrapping\n",
      "│       │   │   └── 2.1.3.8.2 -- Jackknifing\n",
      "│       │   └── 2.1.3.9 -- Random number generation\n",
      "│       ├── 2.1.4 -- Probabilistic algorithms\n",
      "│       ├── 2.1.5 -- Statistical paradigms\n",
      "│       │   ├── 2.1.5.1 -- Queueing theory\n",
      "│       │   ├── 2.1.5.2 -- Contingency table analysis\n",
      "│       │   ├── 2.1.5.3 -- Regression analysis\n",
      "│       │   │   └── 2.1.5.3.1 -- Robust regression\n",
      "│       │   ├── 2.1.5.4 -- Time series analysis\n",
      "│       │   ├── 2.1.5.5 -- Survival analysis\n",
      "│       │   ├── 2.1.5.6 -- Renewal theory\n",
      "│       │   ├── 2.1.5.7 -- Dimensionality reduction\n",
      "│       │   └── 2.1.5.8 -- Cluster analysis\n",
      "│       ├── 2.1.6 -- Stochastic processes\n",
      "│       │   └── 2.1.6.1 -- Markov processes\n",
      "│       ├── 2.1.7 -- Nonparametric statistics\n",
      "│       ├── 2.1.8 -- Distribution functions\n",
      "│       └── 2.1.9 -- Multivariate statistics\n",
      "├── 3 -- Information systems\n",
      "│   ├── 3.1 -- Data management systemsACM-2\n",
      "│   │   ├── 3.1.1 -- Database design and models\n",
      "│   │   │   ├── 3.1.1.1 -- Relational database model\n",
      "│   │   │   ├── 3.1.1.2 -- Entity relationship models\n",
      "│   │   │   ├── 3.1.1.3 -- Graph-based database models\n",
      "│   │   │   │   ├── 3.1.1.3.1 -- Hierarchical data models\n",
      "│   │   │   │   └── 3.1.1.3.2 -- Network data models\n",
      "│   │   │   ├── 3.1.1.4 -- Physical data models\n",
      "│   │   │   └── 3.1.1.5 -- Data model extensions\n",
      "│   │   │       ├── 3.1.1.5.1 -- Semi-structured data\n",
      "│   │   │       ├── 3.1.1.5.2 -- Data streams\n",
      "│   │   │       ├── 3.1.1.5.3 -- Data provenance\n",
      "│   │   │       └── 3.1.1.5.4 -- Incomplete data\n",
      "│   │   ├── 3.1.2 -- Data structures\n",
      "│   │   │   ├── 3.1.2.1 -- Data access methods\n",
      "│   │   │   │   ├── 3.1.2.1.1 -- Multidimensional range search\n",
      "│   │   │   │   ├── 3.1.2.1.2 -- Data scans\n",
      "│   │   │   │   ├── 3.1.2.1.3 -- Point lookups\n",
      "│   │   │   │   ├── 3.1.2.1.4 -- Unidimensional range search\n",
      "│   │   │   │   └── 3.1.2.1.5 -- Proximity search\n",
      "│   │   │   └── 3.1.2.2 -- Data layout\n",
      "│   │   │       ├── 3.1.2.2.1 -- Data compression\n",
      "│   │   │       ├── 3.1.2.2.2 -- Data encryption\n",
      "│   │   │       └── 3.1.2.2.3 -- Record and block layout\n",
      "│   │   ├── 3.1.3 -- Database management system engines\n",
      "│   │   │   ├── 3.1.3.1 -- DBMS engine architectures\n",
      "│   │   │   ├── 3.1.3.2 -- Database query processing\n",
      "│   │   │   │   ├── 3.1.3.2.1 -- Query optimization\n",
      "│   │   │   │   └── 3.1.3.2.2 -- Query operators\n",
      "│   │   │   ├── 3.1.3.3 -- Database transaction processing\n",
      "│   │   │   │   ├── 3.1.3.3.1 -- Data locking\n",
      "│   │   │   │   ├── 3.1.3.3.2 -- Transaction logging\n",
      "│   │   │   │   └── 3.1.3.3.3 -- Database recovery\n",
      "│   │   │   ├── 3.1.3.4 -- Record and buffer management\n",
      "│   │   │   ├── 3.1.3.5 -- Parallel and distributed DBMSs\n",
      "│   │   │   │   ├── 3.1.3.5.1 -- Key-value stores\n",
      "│   │   │   │   ├── 3.1.3.5.2 -- MapReduce-based systems\n",
      "│   │   │   │   └── 3.1.3.5.3 -- Relational parallel and distributed DBMSs\n",
      "│   │   │   ├── 3.1.3.6 -- Triggers and rules\n",
      "│   │   │   ├── 3.1.3.7 -- Database views\n",
      "│   │   │   ├── 3.1.3.8 -- Integrity checking\n",
      "│   │   │   └── 3.1.3.9 -- Distributed database transactions\n",
      "│   │   │       ├── 3.1.3.9.1 -- Distributed data locking\n",
      "│   │   │       └── 3.1.3.9.2 -- Deadlocks\n",
      "│   │   ├── 3.1.4 -- Query languages\n",
      "│   │   │   ├── 3.1.4.1 -- Relational database query languages\n",
      "│   │   │   │   └── 3.1.4.1.1 -- Structured Query Language\n",
      "│   │   │   ├── 3.1.4.2 -- XML query languages\n",
      "│   │   │   │   ├── 3.1.4.2.1 -- XPath\n",
      "│   │   │   │   └── 3.1.4.2.2 -- XQuery\n",
      "│   │   │   ├── 3.1.4.3 -- Query languages for non-relational engines\n",
      "│   │   │   │   └── 3.1.4.3.1 -- MapReduce languages\n",
      "│   │   │   └── 3.1.4.4 -- Call level interfaces\n",
      "│   │   └── 3.1.5 -- Information integration\n",
      "│   │       ├── 3.1.5.1 -- Deduplication\n",
      "│   │       └── 3.1.5.2 -- Extraction transformation and loading\n",
      "│   ├── 3.2 -- Information systems applications\n",
      "│   │   └── 3.2.1 -- Data mining\n",
      "│   │       ├── 3.2.1.1 -- Data cleaning\n",
      "│   │       ├── 3.2.1.2 -- Collaborative filtering\n",
      "│   │       │   ├── 3.2.1.2.1 -- Item-based\n",
      "│   │       │   └── 3.2.1.2.2 -- Scalable\n",
      "│   │       ├── 3.2.1.3 -- Association rules\n",
      "│   │       │   ├── 3.2.1.3.1 -- Types of association rules\n",
      "│   │       │   ├── 3.2.1.3.2 -- Interestingness\n",
      "│   │       │   └── 3.2.1.3.3 -- Parallel computation\n",
      "│   │       ├── 3.2.1.4 -- Clustering\n",
      "│   │       │   ├── 3.2.1.4.1 -- Massive data clustering\n",
      "│   │       │   ├── 3.2.1.4.2 -- Consensus clustering\n",
      "│   │       │   ├── 3.2.1.4.3 -- Fuzzy clustering\n",
      "│   │       │   ├── 3.2.1.4.4 -- Additive clustering\n",
      "│   │       │   ├── 3.2.1.4.5 -- Feature weight clustering\n",
      "│   │       │   ├── 3.2.1.4.6 -- Conceptual clustering\n",
      "│   │       │   └── 3.2.1.4.7 -- Biclustering\n",
      "│   │       ├── 3.2.1.5 -- Nearest-neighbor search\n",
      "│   │       ├── 3.2.1.6 -- Data stream mining\n",
      "│   │       ├── 3.2.1.7 -- Graph mining\n",
      "│   │       │   ├── 3.2.1.7.1 -- Graph partitioning\n",
      "│   │       │   ├── 3.2.1.7.2 -- Frequent graph mining\n",
      "│   │       │   ├── 3.2.1.7.3 -- Graph based conceptual clustering\n",
      "│   │       │   ├── 3.2.1.7.4 -- Anomaly detection\n",
      "│   │       │   └── 3.2.1.7.5 -- Critical nodes detection\n",
      "│   │       ├── 3.2.1.8 -- Process mining\n",
      "│   │       ├── 3.2.1.11 -- Text mining\n",
      "│   │       │   ├── 3.2.1.11.1 -- Text categorization\n",
      "│   │       │   └── 3.2.1.11.2 -- Key-phrase indexing\n",
      "│   │       ├── 3.2.1.10 -- Data mining tools\n",
      "│   │       ├── 3.2.1.9 -- Sequence mining\n",
      "│   │       │   ├── 3.2.1.9.1 -- Rule and pattern discovery\n",
      "│   │       │   ├── 3.2.1.9.2 -- Trajectory clustering\n",
      "│   │       │   └── 3.2.1.9.3 -- Market graph\n",
      "│   │       └── 3.2.1.12 -- Formal concept analysis\n",
      "│   ├── 3.3 -- World Wide Web\n",
      "│   │   └── 3.3.1 -- Web mining\n",
      "│   │       ├── 3.3.1.2 -- Site wrapping\n",
      "│   │       ├── 3.3.1.3 -- Data extraction and integration\n",
      "│   │       │   ├── 3.3.1.3.1 -- Deep web\n",
      "│   │       │   ├── 3.3.1.3.2 -- Surfacing\n",
      "│   │       │   └── 3.3.1.3.3 -- Search results deduplication\n",
      "│   │       ├── 3.3.1.4 -- Web log analysis\n",
      "│   │       ├── 3.3.1.5 -- Traffic analysis\n",
      "│   │       └── 3.3.1.6 -- Knowledge discovery\n",
      "│   └── 3.4 -- Information retrieval\n",
      "│       ├── 3.4.1 -- Document representation\n",
      "│       │   ├── 3.4.1.1 -- Document structure\n",
      "│       │   ├── 3.4.1.2 -- Document topic models\n",
      "│       │   ├── 3.4.1.3 -- Content analysis and feature selection\n",
      "│       │   ├── 3.4.1.4 -- Data encoding and canonicalization\n",
      "│       │   ├── 3.4.1.5 -- Document collection models\n",
      "│       │   ├── 3.4.1.6 -- Ontologies\n",
      "│       │   ├── 3.4.1.7 -- Dictionaries\n",
      "│       │   └── 3.4.1.8 -- Thesauri\n",
      "│       ├── 3.4.2 -- Information retrieval query processing\n",
      "│       │   ├── 3.4.2.1 -- Query representationACM-4\n",
      "│       │   ├── 3.4.2.2 -- Query intent\n",
      "│       │   ├── 3.4.2.3 -- Query log analysis\n",
      "│       │   ├── 3.4.2.4 -- Query suggestion\n",
      "│       │   └── 3.4.2.5 -- Query reformulation\n",
      "│       ├── 3.4.3 -- Users and interactive retrieval\n",
      "│       │   ├── 3.4.3.1 -- Personalization\n",
      "│       │   ├── 3.4.3.2 -- Task models\n",
      "│       │   ├── 3.4.3.3 -- Search interfaces\n",
      "│       │   └── 3.4.3.4 -- Collaborative search\n",
      "│       ├── 3.4.4 -- Retrieval models and ranking\n",
      "│       │   ├── 3.4.4.1 -- Rank aggregation\n",
      "│       │   ├── 3.4.4.2 -- Probabilistic retrieval models\n",
      "│       │   ├── 3.4.4.3 -- Language models\n",
      "│       │   ├── 3.4.4.4 -- Similarity measures\n",
      "│       │   ├── 3.4.4.5 -- Learning to rank\n",
      "│       │   ├── 3.4.4.6 -- Combination fusion and federated search\n",
      "│       │   ├── 3.4.4.7 -- Information retrieval diversity\n",
      "│       │   ├── 3.4.4.8 -- Top-k retrieval in databases\n",
      "│       │   └── 3.4.4.9 -- Novelty in information retrieval\n",
      "│       ├── 3.4.5 -- Retrieval tasks and goals\n",
      "│       │   ├── 3.4.5.1 -- Question answering\n",
      "│       │   ├── 3.4.5.2 -- Document filtering\n",
      "│       │   ├── 3.4.5.3 -- Recommender systems\n",
      "│       │   ├── 3.4.5.4 -- Information extraction\n",
      "│       │   ├── 3.4.5.5 -- Sentiment analysis\n",
      "│       │   ├── 3.4.5.6 -- Expert search\n",
      "│       │   ├── 3.4.5.7 -- Near-duplicate and plagiarism detection\n",
      "│       │   ├── 3.4.5.8 -- Clustering and classification\n",
      "│       │   ├── 3.4.5.9 -- Summarization\n",
      "│       │   └── 3.4.5.10 -- Business intelligence\n",
      "│       ├── 3.4.6 -- Evaluation of retrieval results\n",
      "│       │   ├── 3.4.6.1 -- Test collections\n",
      "│       │   ├── 3.4.6.2 -- Relevance assessment\n",
      "│       │   ├── 3.4.6.3 -- Retrieval effectiveness\n",
      "│       │   ├── 3.4.6.4 -- Retrieval efficiency\n",
      "│       │   └── 3.4.6.5 -- Presentation of retrieval results\n",
      "│       └── 3.4.7 -- Specialized information retrieval\n",
      "│           ├── 3.4.7.1 -- Structure and multilingual text search\n",
      "│           │   ├── 3.4.7.1.1 -- Structured text search\n",
      "│           │   ├── 3.4.7.1.2 -- Mathematics retrieval\n",
      "│           │   ├── 3.4.7.1.3 -- Chemical and biochemical retrieval\n",
      "│           │   └── 3.4.7.1.4 -- Multilingual and cross-lingual retrieval\n",
      "│           ├── 3.4.7.2 -- Multimedia and multimodal retrieval\n",
      "│           │   ├── 3.4.7.2.1 -- Image search\n",
      "│           │   ├── 3.4.7.2.2 -- Video search\n",
      "│           │   ├── 3.4.7.2.3 -- Speech audio search\n",
      "│           │   └── 3.4.7.2.4 -- Music retrieval\n",
      "│           └── 3.4.7.3 -- Environment-specific retrieval\n",
      "│               ├── 3.4.7.3.1 -- Enterprise search\n",
      "│               ├── 3.4.7.3.2 -- Desktop search\n",
      "│               └── 3.4.7.3.3 -- Web and social media search\n",
      "├── 4 -- Human-centered computing\n",
      "│   └── 4.1 -- Visualization\n",
      "│       ├── 4.1.2 -- Visualization techniques\n",
      "│       │   ├── 4.1.2.1 -- Treemaps\n",
      "│       │   ├── 4.1.2.2 -- Hyperbolic trees\n",
      "│       │   ├── 4.1.2.3 -- Heat maps\n",
      "│       │   ├── 4.1.2.4 -- Graph drawings\n",
      "│       │   ├── 4.1.2.5 -- Dendrograms\n",
      "│       │   └── 4.1.2.6 -- Cladograms\n",
      "│       ├── 4.1.3 -- Visualization application domains\n",
      "│       │   ├── 4.1.3.1 -- Scientific visualization\n",
      "│       │   ├── 4.1.3.2 -- Visual analytics\n",
      "│       │   ├── 4.1.3.3 -- Geographic visualization\n",
      "│       │   └── 4.1.3.4 -- Information visualization\n",
      "│       ├── 4.1.4 -- Visualization systems and tools\n",
      "│       │   └── 4.1.4.1 -- Visualization toolkits\n",
      "│       ├── 4.1.5 -- Visualization theory concepts and paradigms\n",
      "│       ├── 4.1.6 -- Empirical studies in visualization\n",
      "│       └── 4.1.7 -- Visualization design and evaluation methods\n",
      "└── 5 -- Computing methodologies\n",
      "    ├── 5.1 -- Artificial intelligence\n",
      "    │   ├── 5.1.1 -- Natural language processing\n",
      "    │   │   ├── 5.1.1.2 -- Information extraction\n",
      "    │   │   ├── 5.1.1.3 -- Machine translation\n",
      "    │   │   ├── 5.1.1.4 -- Discourse dialogue and pragmatics\n",
      "    │   │   ├── 5.1.1.5 -- Natural language generation\n",
      "    │   │   ├── 5.1.1.6 -- Speech recognition\n",
      "    │   │   ├── 5.1.1.7 -- Lexical semantics\n",
      "    │   │   │   └── 5.1.1.7.1 -- Wikipedia based semantics\n",
      "    │   │   ├── 5.1.1.8 -- Phonology morphology\n",
      "    │   │   └── 5.1.1.9 -- Language resources\n",
      "    │   ├── 5.1.2 -- Knowledge representation and reasoning\n",
      "    │   │   ├── 5.1.2.1 -- Description logics\n",
      "    │   │   ├── 5.1.2.2 -- Semantic networks\n",
      "    │   │   ├── 5.1.2.3 -- Nonmonotonic default reasoning and belief revision\n",
      "    │   │   ├── 5.1.2.4 -- Probabilistic reasoning\n",
      "    │   │   ├── 5.1.2.5 -- Vagueness and fuzzy logic\n",
      "    │   │   └── 5.1.2.6 -- Causal reasoning and diagnostics\n",
      "    │   └── 5.1.3 -- Computer vision\n",
      "    │       ├── 5.1.3.1 -- Computer vision problems\n",
      "    │       │   ├── 5.1.3.1.1 -- Interest point and salient region detections\n",
      "    │       │   ├── 5.1.3.1.2 -- Image segmentationACM-6\n",
      "    │       │   ├── 5.1.3.1.3 -- Video segmentation\n",
      "    │       │   ├── 5.1.3.1.4 -- Shape inference\n",
      "    │       │   ├── 5.1.3.1.5 -- Object detection\n",
      "    │       │   ├── 5.1.3.1.6 -- Object recognition\n",
      "    │       │   └── 5.1.3.1.7 -- Object identification\n",
      "    │       └── 5.1.3.2 -- Computer vision representations\n",
      "    │           ├── 5.1.3.2.1 -- Image representations\n",
      "    │           │   └── 5.1.3.2.1.1 -- 2D PCA\n",
      "    │           ├── 5.1.3.2.2 -- Shape representations\n",
      "    │           ├── 5.1.3.2.3 -- Appearance and texture representations\n",
      "    │           └── 5.1.3.2.4 -- Hierarchical representations\n",
      "    └── 5.2 -- Machine learning\n",
      "        ├── 5.2.1 -- Learning paradigms\n",
      "        │   ├── 5.2.1.1 -- Supervised learning\n",
      "        │   │   ├── 5.2.1.1.1 -- Ranking\n",
      "        │   │   ├── 5.2.1.1.2 -- Learning to rank\n",
      "        │   │   ├── 5.2.1.1.3 -- Supervised learning by classification\n",
      "        │   │   └── 5.2.1.1.4 -- Supervised learning by regression\n",
      "        │   ├── 5.2.1.2 -- Unsupervised learning\n",
      "        │   │   ├── 5.2.1.2.1 -- Cluster analysis\n",
      "        │   │   ├── 5.2.1.2.2 -- Anomaly detection\n",
      "        │   │   ├── 5.2.1.2.3 -- Mixture modeling\n",
      "        │   │   ├── 5.2.1.2.4 -- Topic modeling\n",
      "        │   │   ├── 5.2.1.2.5 -- Source separation\n",
      "        │   │   ├── 5.2.1.2.6 -- Motif discovery\n",
      "        │   │   └── 5.2.1.2.7 -- Dimensionality reduction and manifold learning\n",
      "        │   │       ├── 5.2.1.2.7.1 -- Graph embedding\n",
      "        │   │       └── 5.2.1.2.7.2 -- Supervised dimesionality reduction\n",
      "        │   ├── 5.2.1.3 -- Reinforcement learning\n",
      "        │   │   ├── 5.2.1.3.1 -- Sequential decision making\n",
      "        │   │   ├── 5.2.1.3.2 -- Inverse reinforcement learning\n",
      "        │   │   ├── 5.2.1.3.3 -- Apprenticeship learning\n",
      "        │   │   ├── 5.2.1.3.4 -- Multi-agent reinforcement learning\n",
      "        │   │   └── 5.2.1.3.5 -- Adversarial learning\n",
      "        │   └── 5.2.1.4 -- Multi-task learning\n",
      "        │       ├── 5.2.1.4.1 -- Transfer learning\n",
      "        │       ├── 5.2.1.4.2 -- Lifelong machine learning\n",
      "        │       └── 5.2.1.4.3 -- Learning under covariate shift\n",
      "        ├── 5.2.2 -- Learning settings\n",
      "        │   ├── 5.2.2.1 -- Batch learning\n",
      "        │   ├── 5.2.2.2 -- Online learning settings\n",
      "        │   └── 5.2.2.3 -- Learning from demonstrations\n",
      "        ├── 5.2.3 -- Machine learning approaches\n",
      "        │   ├── 5.2.3.1 -- Classification and regression trees\n",
      "        │   │   ├── 5.2.3.1.1 -- Parallel implementation\n",
      "        │   │   ├── 5.2.3.1.2 -- Splittting criteria\n",
      "        │   │   └── 5.2.3.1.3 -- Model trees\n",
      "        │   ├── 5.2.3.2 -- Kernel methods\n",
      "        │   │   ├── 5.2.3.2.1 -- Kernel support vector machines\n",
      "        │   │   │   └── 5.2.3.2.1.1 -- Dynamic\n",
      "        │   │   ├── 5.2.3.2.2 -- Gaussian processes\n",
      "        │   │   ├── 5.2.3.2.3 -- Kernel Matrix\n",
      "        │   │   ├── 5.2.3.2.4 -- Kernel Independent components\n",
      "        │   │   └── 5.2.3.2.5 -- Kernel-based clustering\n",
      "        │   ├── 5.2.3.3 -- Neural networks\n",
      "        │   │   ├── 5.2.3.3.1 -- Self organized map\n",
      "        │   │   ├── 5.2.3.3.2 -- Training approaches\n",
      "        │   │   │   └── 5.2.3.3.2.1 -- Evolutionary approach\n",
      "        │   │   ├── 5.2.3.3.3 -- Representation\n",
      "        │   │   │   ├── 5.2.3.3.3.1 -- Rule-based netwok archirtecture\n",
      "        │   │   │   └── 5.2.3.3.3.2 -- Fuzzy representation\n",
      "        │   │   ├── 5.2.3.3.4 -- Evolving NN\n",
      "        │   │   └── 5.2.3.3.5 -- Ensembling\n",
      "        │   ├── 5.2.3.4 -- Logical and relational learningACM-7\n",
      "        │   │   ├── 5.2.3.4.1 -- Inductive logic learning\n",
      "        │   │   └── 5.2.3.4.2 -- Statistical relational learning\n",
      "        │   ├── 5.2.3.5 -- Learning in probabilistic graphical models\n",
      "        │   │   ├── 5.2.3.5.1 -- Maximum likelihood modeling\n",
      "        │   │   ├── 5.2.3.5.2 -- Maximum entropy modeling\n",
      "        │   │   ├── 5.2.3.5.3 -- Maximum a posteriori modeling\n",
      "        │   │   ├── 5.2.3.5.4 -- Mixture models\n",
      "        │   │   ├── 5.2.3.5.5 -- Latent variable models\n",
      "        │   │   ├── 5.2.3.5.6 -- Bayesian network models\n",
      "        │   │   └── 5.2.3.5.7 -- Markov network models\n",
      "        │   ├── 5.2.3.6 -- Learning linear models\n",
      "        │   │   ├── 5.2.3.6.1 -- Perceptron algorithm\n",
      "        │   │   └── 5.2.3.6.2 -- Linear Discriminant Analysis\n",
      "        │   │       └── 5.2.3.6.2.1 -- Tensor representation\n",
      "        │   ├── 5.2.3.7 -- Factorization methods\n",
      "        │   │   ├── 5.2.3.7.1 -- Non-negative matrix factorization\n",
      "        │   │   ├── 5.2.3.7.2 -- Factor analysis\n",
      "        │   │   ├── 5.2.3.7.3 -- Principal component analysis\n",
      "        │   │   │   ├── 5.2.3.7.3.1 -- 2D PCA\n",
      "        │   │   │   └── 5.2.3.7.3.2 -- Sparse PCA\n",
      "        │   │   ├── 5.2.3.7.4 -- Canonical correlation analysis\n",
      "        │   │   ├── 5.2.3.7.6 -- Latent Dirichlet allocation\n",
      "        │   │   ├── 5.2.3.7.8 -- Independent Component Analysis\n",
      "        │   │   ├── 5.2.3.7.9 -- Nonlinear Principal Components\n",
      "        │   │   └── 5.2.3.7.10 -- Multidimentional scaling\n",
      "        │   │       └── 5.2.3.7.10.1 -- Least moduli\n",
      "        │   ├── 5.2.3.8 -- Rule learning\n",
      "        │   │   └── 5.2.3.8.1 -- Neuro-fuzzy approach\n",
      "        │   ├── 5.2.3.9 -- Instance-based learning\n",
      "        │   ├── 5.2.3.10 -- Markov decision processes\n",
      "        │   ├── 5.2.3.11 -- Partially-observable Markov decision processes\n",
      "        │   ├── 5.2.3.12 -- Stochastic games\n",
      "        │   ├── 5.2.3.13 -- Learning latent representations\n",
      "        │   ├── 5.2.3.14 -- Multiresolution\n",
      "        │   └── 5.2.3.15 -- Support vector machines\n",
      "        ├── 5.2.4 -- Machine learning algorithms\n",
      "        │   ├── 5.2.4.1 -- Dynamic programming for Markov decision processes\n",
      "        │   │   ├── 5.2.4.1.1 -- Value iteration\n",
      "        │   │   ├── 5.2.4.1.2 -- Q-learning\n",
      "        │   │   ├── 5.2.4.1.3 -- Policy iteration\n",
      "        │   │   ├── 5.2.4.1.4 -- Temporal difference learning\n",
      "        │   │   └── 5.2.4.1.5 -- Approximate dynamic programming methods\n",
      "        │   ├── 5.2.4.2 -- Ensemble methods\n",
      "        │   │   ├── 5.2.4.2.1 -- Boosting\n",
      "        │   │   ├── 5.2.4.2.2 -- Bagging\n",
      "        │   │   └── 5.2.4.2.3 -- Fusion of classifiers\n",
      "        │   ├── 5.2.4.3 -- Spectral methods\n",
      "        │   │   └── 5.2.4.3.1 -- Spectral clustering\n",
      "        │   ├── 5.2.4.4 -- Feature selection\n",
      "        │   └── 5.2.4.5 -- Regularization\n",
      "        │       └── 5.2.4.5.1 -- Generalized eigenvalue\n",
      "        └── 5.2.5 -- Cross-validation\n"
     ]
    }
   ],
   "source": [
    "save_taxonomy_txt(root, 'visualization/taxonomies/taxonomy_vis_dfs.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      "├── 1 -- Theory of computation\n",
      "│   └── 1.1 -- Theory and algorithms for application domains\n",
      "│       ├── 1.1.1 -- Machine learning theory\n",
      "│       │   ├── 1.1.1.1 -- Sample complexity and generalization bounds\n",
      "│       │   ├── 1.1.1.2 -- Boolean function learning\n",
      "│       │   ├── 1.1.1.3 -- Unsupervised learning and clustering\n",
      "│       │   ├── 1.1.1.4 -- Kernel methods\n",
      "│       │   │   ├── 1.1.1.4.1 -- Support vector machines\n",
      "│       │   │   ├── 1.1.1.4.2 -- Gaussian processes\n",
      "│       │   │   └── 1.1.1.4.3 -- Modelling\n",
      "│       │   ├── 1.1.1.5 -- Boosting\n",
      "│       │   ├── 1.1.1.6 -- Bayesian analysis\n",
      "│       │   ├── 1.1.1.7 -- Inductive inference\n",
      "│       │   ├── 1.1.1.8 -- Online learning theory\n",
      "│       │   ├── 1.1.1.9 -- Multi-agent learning\n",
      "│       │   ├── 1.1.1.10 -- Models of learning\n",
      "│       │   ├── 1.1.1.11 -- Query learning\n",
      "│       │   ├── 1.1.1.12 -- Structured prediction\n",
      "│       │   ├── 1.1.1.13 -- Reinforcement learning\n",
      "│       │   │   ├── 1.1.1.13.1 -- Sequential decision making\n",
      "│       │   │   ├── 1.1.1.13.2 -- Inverse reinforcement learning\n",
      "│       │   │   ├── 1.1.1.13.3 -- Apprenticeship learning\n",
      "│       │   │   ├── 1.1.1.13.4 -- Multi-agent reinforcement learning\n",
      "│       │   │   └── 1.1.1.13.5 -- Adversarial learning\n",
      "│       │   ├── 1.1.1.14 -- Active learning\n",
      "│       │   ├── 1.1.1.15 -- Semi-supervised learning\n",
      "│       │   ├── 1.1.1.16 -- Markov decision processes\n",
      "│       │   └── 1.1.1.17 -- Regret bounds\n",
      "│       └── 1.1.2 -- Database theory\n",
      "│           ├── 1.1.2.1 -- Data exchange\n",
      "│           ├── 1.1.2.2 -- Data provenance\n",
      "│           ├── 1.1.2.3 -- Data modeling\n",
      "│           ├── 1.1.2.4 -- Database query languages principles\n",
      "│           ├── 1.1.2.5 -- Database constraints theory\n",
      "│           ├── 1.1.2.6 -- Database interoperability\n",
      "│           ├── 1.1.2.7 -- Data structures and algorithms for data management\n",
      "│           ├── 1.1.2.8 -- Database query processing and optimization theory\n",
      "│           ├── 1.1.2.9 -- Data integration\n",
      "│           ├── 1.1.2.10 -- Logic and databases\n",
      "│           ├── 1.1.2.11 -- Theory of database privacy and security\n",
      "│           └── 1.1.2.12 -- Incomplete inconsistent and uncertain databases\n",
      "├── 2 -- Mathematics of computing\n",
      "│   └── 2.1 -- Probability and statistics\n",
      "│       ├── 2.1.1 -- Probabilistic representations\n",
      "│       │   ├── 2.1.1.1 -- Bayesian networks\n",
      "│       │   ├── 2.1.1.2 -- Markov networks\n",
      "│       │   ├── 2.1.1.3 -- Factor graphs\n",
      "│       │   ├── 2.1.1.4 -- Decision diagrams\n",
      "│       │   ├── 2.1.1.5 -- Equational models\n",
      "│       │   ├── 2.1.1.6 -- Causal networksACM-1\n",
      "│       │   ├── 2.1.1.7 -- Stochastic differential equations\n",
      "│       │   └── 2.1.1.8 -- Nonparametric representations\n",
      "│       │       ├── 2.1.1.8.1 -- Kernel density estimators\n",
      "│       │       ├── 2.1.1.8.2 -- Spline models\n",
      "│       │       └── 2.1.1.8.3 -- Bayesian nonparametric models\n",
      "│       ├── 2.1.2 -- Probabilistic inference problems\n",
      "│       │   ├── 2.1.2.1 -- Maximum likelihood estimation\n",
      "│       │   ├── 2.1.2.2 -- Bayesian computation\n",
      "│       │   ├── 2.1.2.3 -- Computing most probable explanation\n",
      "│       │   ├── 2.1.2.4 -- Hypothesis testing and confidence interval computation\n",
      "│       │   ├── 2.1.2.5 -- Density estimation\n",
      "│       │   │   └── 2.1.2.5.1 -- Quantile regression\n",
      "│       │   └── 2.1.2.6 -- Max marginal computation\n",
      "│       ├── 2.1.3 -- Probabilistic reasoning algorithms\n",
      "│       │   ├── 2.1.3.1 -- Variable elimination\n",
      "│       │   ├── 2.1.3.2 -- Loopy belief propagation\n",
      "│       │   ├── 2.1.3.3 -- Variational methods\n",
      "│       │   ├── 2.1.3.4 -- Expectation maximization\n",
      "│       │   ├── 2.1.3.5 -- Markov-chain Monte Carlo methods\n",
      "│       │   │   ├── 2.1.3.5.1 -- Gibbs sampling\n",
      "│       │   │   ├── 2.1.3.5.2 -- Metropolis-Hastings algorithm\n",
      "│       │   │   ├── 2.1.3.5.3 -- Simulated annealing\n",
      "│       │   │   └── 2.1.3.5.4 -- Markov-chain Monte Carlo convergence measures\n",
      "│       │   ├── 2.1.3.6 -- Sequential Monte Carlo methods\n",
      "│       │   ├── 2.1.3.7 -- Kalman filters and hidden Markov models\n",
      "│       │   │   └── 2.1.3.7.1 -- Factorial HMM\n",
      "│       │   ├── 2.1.3.8 -- Resampling methods\n",
      "│       │   │   ├── 2.1.3.8.1 -- Bootstrapping\n",
      "│       │   │   └── 2.1.3.8.2 -- Jackknifing\n",
      "│       │   └── 2.1.3.9 -- Random number generation\n",
      "│       ├── 2.1.4 -- Probabilistic algorithms\n",
      "│       ├── 2.1.5 -- Statistical paradigms\n",
      "│       │   ├── 2.1.5.1 -- Queueing theory\n",
      "│       │   ├── 2.1.5.2 -- Contingency table analysis\n",
      "│       │   ├── 2.1.5.3 -- Regression analysis\n",
      "│       │   │   └── 2.1.5.3.1 -- Robust regression\n",
      "│       │   ├── 2.1.5.4 -- Time series analysis\n",
      "│       │   ├── 2.1.5.5 -- Survival analysis\n",
      "│       │   ├── 2.1.5.6 -- Renewal theory\n",
      "│       │   ├── 2.1.5.7 -- Dimensionality reduction\n",
      "│       │   ├── 2.1.5.8 -- Cluster analysis\n",
      "│       │   ├── 2.1.5.9 -- Statistical graphics\n",
      "│       │   └── 2.1.5.10 -- Exploratory data analysis\n",
      "│       ├── 2.1.6 -- Stochastic processes\n",
      "│       │   └── 2.1.6.1 -- Markov processes\n",
      "│       ├── 2.1.7 -- Nonparametric statistics\n",
      "│       ├── 2.1.8 -- Distribution functions\n",
      "│       └── 2.1.9 -- Multivariate statistics\n",
      "├── 3 -- Information systems\n",
      "│   └── 3.1 -- Data management systemsACM-2\n",
      "│       ├── 3.1.1 -- Database design and models\n",
      "│       │   ├── 3.1.1.1 -- Relational database model\n",
      "│       │   ├── 3.1.1.2 -- Entity relationship models\n",
      "│       │   ├── 3.1.1.3 -- Graph-based database models\n",
      "│       │   │   ├── 3.1.1.3.1 -- Hierarchical data models\n",
      "│       │   │   └── 3.1.1.3.2 -- Network data models\n",
      "│       │   ├── 3.1.1.4 -- Physical data models\n",
      "│       │   └── 3.1.1.5 -- Data model extensions\n",
      "│       │       ├── 3.1.1.5.1 -- Semi-structured data\n",
      "│       │       ├── 3.1.1.5.2 -- Data streams\n",
      "│       │       ├── 3.1.1.5.3 -- Data provenance\n",
      "│       │       ├── 3.1.1.5.4 -- Incomplete data\n",
      "│       │       ├── 3.1.1.5.5 -- Temporal data\n",
      "│       │       ├── 3.1.1.5.6 -- Uncertainty\n",
      "│       │       └── 3.1.1.5.7 -- Inconsistent data\n",
      "│       ├── 3.1.2 -- Data structures\n",
      "│       │   ├── 3.1.2.1 -- Data access methods\n",
      "│       │   │   ├── 3.1.2.1.1 -- Multidimensional range search\n",
      "│       │   │   ├── 3.1.2.1.2 -- Data scans\n",
      "│       │   │   ├── 3.1.2.1.3 -- Point lookups\n",
      "│       │   │   ├── 3.1.2.1.4 -- Unidimensional range search\n",
      "│       │   │   └── 3.1.2.1.5 -- Proximity search\n",
      "│       │   └── 3.1.2.2 -- Data layout\n",
      "│       │       ├── 3.1.2.2.1 -- Data compression\n",
      "│       │       ├── 3.1.2.2.2 -- Data encryption\n",
      "│       │       └── 3.1.2.2.3 -- Record and block layout\n",
      "│       ├── 3.1.3 -- Database management system engines\n",
      "│       │   ├── 3.1.3.1 -- DBMS engine architectures\n",
      "│       │   ├── 3.1.3.2 -- Database query processing\n",
      "│       │   │   ├── 3.1.3.2.1 -- Query optimization\n",
      "│       │   │   ├── 3.1.3.2.2 -- Query operators\n",
      "│       │   │   ├── 3.1.3.2.3 -- Query planning\n",
      "│       │   │   └── 3.1.3.2.3 -- Join algorithms\n",
      "│       │   ├── 3.1.3.3 -- Database transaction processing\n",
      "│       │   │   ├── 3.1.3.3.1 -- Data locking\n",
      "│       │   │   ├── 3.1.3.3.2 -- Transaction logging\n",
      "│       │   │   └── 3.1.3.3.3 -- Database recovery\n",
      "│       │   ├── 3.1.3.4 -- Record and buffer management\n",
      "│       │   ├── 3.1.3.5 -- Parallel and distributed DBMSs\n",
      "│       │   │   ├── 3.1.3.5.1 -- Key-value stores\n",
      "│       │   │   ├── 3.1.3.5.2 -- MapReduce-based systems\n",
      "│       │   │   └── 3.1.3.5.3 -- Relational parallel and distributed DBMSs\n",
      "│       │   ├── 3.1.3.6 -- Triggers and rules\n",
      "│       │   ├── 3.1.3.7 -- Database views\n",
      "│       │   ├── 3.1.3.8 -- Integrity checking\n",
      "│       │   ├── 3.1.3.9 -- Distributed database transactions\n",
      "│       │   │   ├── 3.1.3.9.1 -- Distributed data locking\n",
      "│       │   │   ├── 3.1.3.9.2 -- Deadlocks\n",
      "│       │   │   └── 3.1.3.9.3 -- Distributed database recovery\n",
      "│       │   ├── 3.1.3.10 -- Main memory engines\n",
      "│       │   ├── 3.1.3.11 -- Online analytical processing engines\n",
      "│       │   └── 3.1.3.12 -- Stream management\n",
      "│       ├── 3.1.4 -- Query languages\n",
      "│       │   ├── 3.1.4.1 -- Relational database query languages\n",
      "│       │   │   └── 3.1.4.1.1 -- Structured Query Language\n",
      "│       │   ├── 3.1.4.2 -- XML query languages\n",
      "│       │   │   ├── 3.1.4.2.1 -- XPath\n",
      "│       │   │   └── 3.1.4.2.2 -- XQuery\n",
      "│       │   ├── 3.1.4.3 -- Query languages for non-relational engines\n",
      "│       │   │   └── 3.1.4.3.1 -- MapReduce languages\n",
      "│       │   └── 3.1.4.4 -- Call level interfaces\n",
      "│       └── 3.1.5 -- Information integration\n",
      "│           ├── 3.1.5.1 -- Deduplication\n",
      "│           ├── 3.1.5.2 -- Extraction transformation and loading\n",
      "│           ├── 3.1.5.3 -- Data exchange\n",
      "│           ├── 3.1.5.4 -- Data cleaning\n",
      "│           ├── 3.1.5.5 -- Wrappers data mining\n",
      "│           ├── 3.1.5.6 -- Mediators and data integration\n",
      "│           ├── 3.1.5.7 -- Entity resolution\n",
      "│           └── 3.1.5.8 -- Data warehouses\n",
      "├── 1.1.5.9 -- Federated databases\n",
      "│   ├── 3.2 -- Information systems applications\n",
      "│   │   └── 3.2.1 -- Data mining\n",
      "│   │       ├── 3.2.1.1 -- Data cleaning\n",
      "│   │       ├── 3.2.1.2 -- Collaborative filtering\n",
      "│   │       │   ├── 3.2.1.2.1 -- Item-based\n",
      "│   │       │   └── 3.2.1.2.2 -- Scalable\n",
      "│   │       ├── 3.2.1.3 -- Association rules\n",
      "│   │       │   ├── 3.2.1.3.1 -- Types of association rules\n",
      "│   │       │   ├── 3.2.1.3.2 -- Interestingness\n",
      "│   │       │   └── 3.2.1.3.3 -- Parallel computation\n",
      "│   │       ├── 3.2.1.4 -- Clustering\n",
      "│   │       │   ├── 3.2.1.4.1 -- Massive data clustering\n",
      "│   │       │   ├── 3.2.1.4.2 -- Consensus clustering\n",
      "│   │       │   ├── 3.2.1.4.3 -- Fuzzy clustering\n",
      "│   │       │   ├── 3.2.1.4.4 -- Additive clustering\n",
      "│   │       │   ├── 3.2.1.4.5 -- Feature weight clustering\n",
      "│   │       │   ├── 3.2.1.4.6 -- Conceptual clustering\n",
      "│   │       │   └── 3.2.1.4.7 -- Biclustering\n",
      "│   │       ├── 3.2.1.5 -- Nearest-neighbor search\n",
      "│   │       ├── 3.2.1.6 -- Data stream mining\n",
      "│   │       ├── 3.2.1.7 -- Graph mining\n",
      "│   │       │   ├── 3.2.1.7.1 -- Graph partitioning\n",
      "│   │       │   ├── 3.2.1.7.2 -- Frequent graph mining\n",
      "│   │       │   ├── 3.2.1.7.3 -- Graph based conceptual clustering\n",
      "│   │       │   ├── 3.2.1.7.4 -- Anomaly detection\n",
      "│   │       │   └── 3.2.1.7.5 -- Critical nodes detection\n",
      "│   │       ├── 3.2.1.8 -- Process mining\n",
      "│   │       ├── 3.2.1.11 -- Text mining\n",
      "│   │       │   ├── 3.2.1.11.1 -- Text categorization\n",
      "│   │       │   └── 3.2.1.11.2 -- Key-phrase indexing\n",
      "│   │       ├── 3.2.1.10 -- Data mining tools\n",
      "│   │       ├── 3.2.1.9 -- Sequence mining\n",
      "│   │       │   ├── 3.2.1.9.1 -- Rule and pattern discovery\n",
      "│   │       │   ├── 3.2.1.9.2 -- Trajectory clustering\n",
      "│   │       │   └── 3.2.1.9.3 -- Market graph\n",
      "│   │       └── 3.2.1.12 -- Formal concept analysis\n",
      "│   ├── 3.3 -- World Wide Web\n",
      "│   │   └── 3.3.1 -- Web mining\n",
      "│   │       ├── 3.3.1.2 -- Site wrapping\n",
      "│   │       ├── 3.3.1.3 -- Data extraction and integration\n",
      "│   │       │   ├── 3.3.1.3.1 -- Deep web\n",
      "│   │       │   ├── 3.3.1.3.2 -- Surfacing\n",
      "│   │       │   └── 3.3.1.3.3 -- Search results deduplication\n",
      "│   │       ├── 3.3.1.4 -- Web log analysis\n",
      "│   │       ├── 3.3.1.5 -- Traffic analysis\n",
      "│   │       └── 3.3.1.6 -- Knowledge discovery\n",
      "│   └── 3.4 -- Information retrieval\n",
      "│       ├── 3.4.1 -- Document representation\n",
      "│       │   ├── 3.4.1.1 -- Document structure\n",
      "│       │   ├── 3.4.1.2 -- Document topic models\n",
      "│       │   ├── 3.4.1.3 -- Content analysis and feature selection\n",
      "│       │   ├── 3.4.1.4 -- Data encoding and canonicalization\n",
      "│       │   ├── 3.4.1.5 -- Document collection models\n",
      "│       │   ├── 3.4.1.6 -- Ontologies\n",
      "│       │   ├── 3.4.1.7 -- Dictionaries\n",
      "│       │   └── 3.4.1.8 -- Thesauri\n",
      "│       ├── 3.4.2 -- Information retrieval query processing\n",
      "│       │   ├── 3.4.2.1 -- Query representationACM-4\n",
      "│       │   ├── 3.4.2.2 -- Query intent\n",
      "│       │   ├── 3.4.2.3 -- Query log analysis\n",
      "│       │   ├── 3.4.2.4 -- Query suggestion\n",
      "│       │   └── 3.4.2.5 -- Query reformulation\n",
      "│       ├── 3.4.3 -- Users and interactive retrieval\n",
      "│       │   ├── 3.4.3.1 -- Personalization\n",
      "│       │   ├── 3.4.3.2 -- Task models\n",
      "│       │   ├── 3.4.3.3 -- Search interfaces\n",
      "│       │   └── 3.4.3.4 -- Collaborative search\n",
      "│       ├── 3.4.4 -- Retrieval models and ranking\n",
      "│       │   ├── 3.4.4.1 -- Rank aggregation\n",
      "│       │   ├── 3.4.4.2 -- Probabilistic retrieval models\n",
      "│       │   ├── 3.4.4.3 -- Language models\n",
      "│       │   ├── 3.4.4.4 -- Similarity measures\n",
      "│       │   ├── 3.4.4.5 -- Learning to rank\n",
      "│       │   ├── 3.4.4.6 -- Combination fusion and federated search\n",
      "│       │   ├── 3.4.4.7 -- Information retrieval diversity\n",
      "│       │   ├── 3.4.4.8 -- Top-k retrieval in databases\n",
      "│       │   └── 3.4.4.9 -- Novelty in information retrieval\n",
      "│       ├── 3.4.5 -- Retrieval tasks and goals\n",
      "│       │   ├── 3.4.5.1 -- Question answering\n",
      "│       │   ├── 3.4.5.2 -- Document filtering\n",
      "│       │   ├── 3.4.5.3 -- Recommender systems\n",
      "│       │   ├── 3.4.5.4 -- Information extraction\n",
      "│       │   ├── 3.4.5.5 -- Sentiment analysis\n",
      "│       │   ├── 3.4.5.6 -- Expert search\n",
      "│       │   ├── 3.4.5.7 -- Near-duplicate and plagiarism detection\n",
      "│       │   ├── 3.4.5.8 -- Clustering and classification\n",
      "│       │   ├── 3.4.5.9 -- Summarization\n",
      "│       │   └── 3.4.5.10 -- Business intelligence\n",
      "│       ├── 3.4.6 -- Evaluation of retrieval results\n",
      "│       │   ├── 3.4.6.1 -- Test collections\n",
      "│       │   ├── 3.4.6.2 -- Relevance assessment\n",
      "│       │   ├── 3.4.6.3 -- Retrieval effectiveness\n",
      "│       │   ├── 3.4.6.4 -- Retrieval efficiency\n",
      "│       │   └── 3.4.6.5 -- Presentation of retrieval results\n",
      "│       └── 3.4.7 -- Specialized information retrieval\n",
      "│           ├── 3.4.7.1 -- Structure and multilingual text search\n",
      "│           │   ├── 3.4.7.1.1 -- Structured text search\n",
      "│           │   ├── 3.4.7.1.2 -- Mathematics retrieval\n",
      "│           │   ├── 3.4.7.1.3 -- Chemical and biochemical retrieval\n",
      "│           │   └── 3.4.7.1.4 -- Multilingual and cross-lingual retrieval\n",
      "│           ├── 3.4.7.2 -- Multimedia and multimodal retrieval\n",
      "│           │   ├── 3.4.7.2.1 -- Image search\n",
      "│           │   ├── 3.4.7.2.2 -- Video search\n",
      "│           │   ├── 3.4.7.2.3 -- Speech audio search\n",
      "│           │   └── 3.4.7.2.4 -- Music retrieval\n",
      "│           └── 3.4.7.3 -- Environment-specific retrieval\n",
      "│               ├── 3.4.7.3.1 -- Enterprise search\n",
      "│               ├── 3.4.7.3.2 -- Desktop search\n",
      "│               └── 3.4.7.3.3 -- Web and social media search\n",
      "├── 4 -- Human-centered computing\n",
      "│   └── 4.1 -- Visualization\n",
      "│       ├── 4.1.2 -- Visualization techniques\n",
      "│       │   ├── 4.1.2.1 -- Treemaps\n",
      "│       │   ├── 4.1.2.2 -- Hyperbolic trees\n",
      "│       │   ├── 4.1.2.3 -- Heat maps\n",
      "│       │   ├── 4.1.2.4 -- Graph drawings\n",
      "│       │   ├── 4.1.2.5 -- Dendrograms\n",
      "│       │   ├── 4.1.2.6 -- Cladograms\n",
      "│       │   └── 4.1.2.7 -- Elastic maps\n",
      "│       ├── 4.1.3 -- Visualization application domains\n",
      "│       │   ├── 4.1.3.1 -- Scientific visualization\n",
      "│       │   ├── 4.1.3.2 -- Visual analytics\n",
      "│       │   ├── 4.1.3.3 -- Geographic visualization\n",
      "│       │   └── 4.1.3.4 -- Information visualization\n",
      "│       ├── 4.1.4 -- Visualization systems and tools\n",
      "│       │   └── 4.1.4.1 -- Visualization toolkits\n",
      "│       ├── 4.1.5 -- Visualization theory concepts and paradigms\n",
      "│       ├── 4.1.6 -- Empirical studies in visualization\n",
      "│       └── 4.1.7 -- Visualization design and evaluation methods\n",
      "└── 5 -- Computing methodologies\n",
      "    ├── 5.1 -- Artificial intelligence\n",
      "    │   ├── 5.1.1 -- Natural language processing\n",
      "    │   │   ├── 5.1.1.2 -- Information extraction\n",
      "    │   │   ├── 5.1.1.3 -- Machine translation\n",
      "    │   │   ├── 5.1.1.4 -- Discourse dialogue and pragmatics\n",
      "    │   │   ├── 5.1.1.5 -- Natural language generation\n",
      "    │   │   ├── 5.1.1.6 -- Speech recognition\n",
      "    │   │   ├── 5.1.1.7 -- Lexical semantics\n",
      "    │   │   │   └── 5.1.1.7.1 -- Wikipedia based semantics\n",
      "    │   │   ├── 5.1.1.8 -- Phonology morphology\n",
      "    │   │   └── 5.1.1.9 -- Language resources\n",
      "    │   ├── 5.1.2 -- Knowledge representation and reasoning\n",
      "    │   │   ├── 5.1.2.1 -- Description logics\n",
      "    │   │   ├── 5.1.2.2 -- Semantic networks\n",
      "    │   │   ├── 5.1.2.3 -- Nonmonotonic default reasoning and belief revision\n",
      "    │   │   ├── 5.1.2.4 -- Probabilistic reasoning\n",
      "    │   │   ├── 5.1.2.5 -- Vagueness and fuzzy logic\n",
      "    │   │   ├── 5.1.2.6 -- Causal reasoning and diagnostics\n",
      "    │   │   ├── 5.1.2.7 -- Temporal reasoning\n",
      "    │   │   ├── 5.1.2.8 -- Cognitive robotics\n",
      "    │   │   ├── 5.1.2.9 -- Ontology engineering\n",
      "    │   │   ├── 5.1.2.10 -- Logic programming and answer set programming\n",
      "    │   │   ├── 5.1.2.11 -- Spatial and physical reasoning\n",
      "    │   │   └── 5.1.2.12 -- Reasoning about belief and knowledge\n",
      "    │   └── 5.1.3 -- Computer vision\n",
      "    │       ├── 5.1.3.1 -- Computer vision problems\n",
      "    │       │   ├── 5.1.3.1.1 -- Interest point and salient region detections\n",
      "    │       │   ├── 5.1.3.1.2 -- Image segmentationACM-6\n",
      "    │       │   ├── 5.1.3.1.3 -- Video segmentation\n",
      "    │       │   ├── 5.1.3.1.4 -- Shape inference\n",
      "    │       │   ├── 5.1.3.1.5 -- Object detection\n",
      "    │       │   ├── 5.1.3.1.6 -- Object recognition\n",
      "    │       │   ├── 5.1.3.1.7 -- Object identification\n",
      "    │       │   ├── 5.1.3.1.8 -- Tracking\n",
      "    │       │   ├── 5.1.3.1.9 -- Reconstruction\n",
      "    │       │   └── 5.1.3.1.10 -- Matching\n",
      "    │       └── 5.1.3.2 -- Computer vision representations\n",
      "    │           ├── 5.1.3.2.1 -- Image representations\n",
      "    │           │   └── 5.1.3.2.1.1 -- 2D PCA\n",
      "    │           ├── 5.1.3.2.2 -- Shape representations\n",
      "    │           ├── 5.1.3.2.3 -- Appearance and texture representations\n",
      "    │           └── 5.1.3.2.4 -- Hierarchical representations\n",
      "    └── 5.2 -- Machine learning\n",
      "        ├── 5.2.1 -- Learning paradigms\n",
      "        │   ├── 5.2.1.1 -- Supervised learning\n",
      "        │   │   ├── 5.2.1.1.1 -- Ranking\n",
      "        │   │   ├── 5.2.1.1.2 -- Learning to rank\n",
      "        │   │   ├── 5.2.1.1.3 -- Supervised learning by classification\n",
      "        │   │   ├── 5.2.1.1.4 -- Supervised learning by regression\n",
      "        │   │   ├── 5.2.1.1.5 -- Structured outputs\n",
      "        │   │   └── 5.2.1.1.6 -- Cost-sensitive learning\n",
      "        │   ├── 5.2.1.2 -- Unsupervised learning\n",
      "        │   │   ├── 5.2.1.2.1 -- Cluster analysis\n",
      "        │   │   ├── 5.2.1.2.2 -- Anomaly detection\n",
      "        │   │   ├── 5.2.1.2.3 -- Mixture modeling\n",
      "        │   │   ├── 5.2.1.2.4 -- Topic modeling\n",
      "        │   │   ├── 5.2.1.2.5 -- Source separation\n",
      "        │   │   ├── 5.2.1.2.6 -- Motif discovery\n",
      "        │   │   └── 5.2.1.2.7 -- Dimensionality reduction and manifold learning\n",
      "        │   │       ├── 5.2.1.2.7.1 -- Graph embedding\n",
      "        │   │       └── 5.2.1.2.7.2 -- Supervised dimesionality reduction\n",
      "        │   ├── 5.2.1.3 -- Reinforcement learning\n",
      "        │   │   ├── 5.2.1.3.1 -- Sequential decision making\n",
      "        │   │   ├── 5.2.1.3.2 -- Inverse reinforcement learning\n",
      "        │   │   ├── 5.2.1.3.3 -- Apprenticeship learning\n",
      "        │   │   ├── 5.2.1.3.4 -- Multi-agent reinforcement learning\n",
      "        │   │   └── 5.2.1.3.5 -- Adversarial learning\n",
      "        │   └── 5.2.1.4 -- Multi-task learning\n",
      "        │       ├── 5.2.1.4.1 -- Transfer learning\n",
      "        │       ├── 5.2.1.4.2 -- Lifelong machine learning\n",
      "        │       └── 5.2.1.4.3 -- Learning under covariate shift\n",
      "        ├── 5.2.2 -- Learning settings\n",
      "        │   ├── 5.2.2.1 -- Batch learning\n",
      "        │   ├── 5.2.2.2 -- Online learning settings\n",
      "        │   ├── 5.2.2.3 -- Learning from demonstrations\n",
      "        │   ├── 5.2.2.4 -- Learning from critiques\n",
      "        │   ├── 5.2.2.5 -- Learning from implicit feedback\n",
      "        │   ├── 5.2.2.6 -- Active learning settings\n",
      "        │   └── 5.2.2.7 -- Semi-supervised learning settings\n",
      "        │       └── 5.2.2.7.1 -- Kernel approach\n",
      "        ├── 5.2.3 -- Machine learning approaches\n",
      "        │   ├── 5.2.3.1 -- Classification and regression trees\n",
      "        │   │   ├── 5.2.3.1.1 -- Parallel implementation\n",
      "        │   │   ├── 5.2.3.1.2 -- Splittting criteria\n",
      "        │   │   └── 5.2.3.1.3 -- Model trees\n",
      "        │   ├── 5.2.3.2 -- Kernel methods\n",
      "        │   │   ├── 5.2.3.2.1 -- Kernel support vector machines\n",
      "        │   │   │   └── 5.2.3.2.1.1 -- Dynamic\n",
      "        │   │   ├── 5.2.3.2.2 -- Gaussian processes\n",
      "        │   │   ├── 5.2.3.2.3 -- Kernel Matrix\n",
      "        │   │   ├── 5.2.3.2.4 -- Kernel Independent components\n",
      "        │   │   └── 5.2.3.2.5 -- Kernel-based clustering\n",
      "        │   ├── 5.2.3.3 -- Neural networks\n",
      "        │   │   ├── 5.2.3.3.1 -- Self organized map\n",
      "        │   │   ├── 5.2.3.3.2 -- Training approaches\n",
      "        │   │   │   └── 5.2.3.3.2.1 -- Evolutionary approach\n",
      "        │   │   ├── 5.2.3.3.3 -- Representation\n",
      "        │   │   │   ├── 5.2.3.3.3.1 -- Rule-based netwok archirtecture\n",
      "        │   │   │   └── 5.2.3.3.3.2 -- Fuzzy representation\n",
      "        │   │   ├── 5.2.3.3.4 -- Evolving NN\n",
      "        │   │   └── 5.2.3.3.5 -- Ensembling\n",
      "        │   ├── 5.2.3.4 -- Logical and relational learningACM-7\n",
      "        │   │   ├── 5.2.3.4.1 -- Inductive logic learning\n",
      "        │   │   └── 5.2.3.4.2 -- Statistical relational learning\n",
      "        │   ├── 5.2.3.5 -- Learning in probabilistic graphical models\n",
      "        │   │   ├── 5.2.3.5.1 -- Maximum likelihood modeling\n",
      "        │   │   ├── 5.2.3.5.2 -- Maximum entropy modeling\n",
      "        │   │   ├── 5.2.3.5.3 -- Maximum a posteriori modeling\n",
      "        │   │   ├── 5.2.3.5.4 -- Mixture models\n",
      "        │   │   ├── 5.2.3.5.5 -- Latent variable models\n",
      "        │   │   ├── 5.2.3.5.6 -- Bayesian network models\n",
      "        │   │   └── 5.2.3.5.7 -- Markov network models\n",
      "        │   ├── 5.2.3.6 -- Learning linear models\n",
      "        │   │   ├── 5.2.3.6.1 -- Perceptron algorithm\n",
      "        │   │   └── 5.2.3.6.2 -- Linear Discriminant Analysis\n",
      "        │   │       └── 5.2.3.6.2.1 -- Tensor representation\n",
      "        │   ├── 5.2.3.7 -- Factorization methods\n",
      "        │   │   ├── 5.2.3.7.1 -- Non-negative matrix factorization\n",
      "        │   │   ├── 5.2.3.7.2 -- Factor analysis\n",
      "        │   │   ├── 5.2.3.7.3 -- Principal component analysis\n",
      "        │   │   │   ├── 5.2.3.7.3.1 -- 2D PCA\n",
      "        │   │   │   └── 5.2.3.7.3.2 -- Sparse PCA\n",
      "        │   │   ├── 5.2.3.7.4 -- Canonical correlation analysis\n",
      "        │   │   ├── 5.2.3.7.6 -- Latent Dirichlet allocation\n",
      "        │   │   ├── 5.2.3.7.8 -- Independent Component Analysis\n",
      "        │   │   ├── 5.2.3.7.9 -- Nonlinear Principal Components\n",
      "        │   │   └── 5.2.3.7.10 -- Multidimentional scaling\n",
      "        │   │       └── 5.2.3.7.10.1 -- Least moduli\n",
      "        │   ├── 5.2.3.8 -- Rule learning\n",
      "        │   │   └── 5.2.3.8.1 -- Neuro-fuzzy approach\n",
      "        │   ├── 5.2.3.9 -- Instance-based learning\n",
      "        │   ├── 5.2.3.10 -- Markov decision processes\n",
      "        │   ├── 5.2.3.11 -- Partially-observable Markov decision processes\n",
      "        │   ├── 5.2.3.12 -- Stochastic games\n",
      "        │   ├── 5.2.3.13 -- Learning latent representations\n",
      "        │   │   └── 5.2.3.13.1 -- Deep belief networks\n",
      "        │   ├── 5.2.3.14 -- Multiresolution\n",
      "        │   └── 5.2.3.15 -- Support vector machines\n",
      "        ├── 5.2.4 -- Machine learning algorithms\n",
      "        │   ├── 5.2.4.1 -- Dynamic programming for Markov decision processes\n",
      "        │   │   ├── 5.2.4.1.1 -- Value iteration\n",
      "        │   │   ├── 5.2.4.1.2 -- Q-learning\n",
      "        │   │   ├── 5.2.4.1.3 -- Policy iteration\n",
      "        │   │   ├── 5.2.4.1.4 -- Temporal difference learning\n",
      "        │   │   └── 5.2.4.1.5 -- Approximate dynamic programming methods\n",
      "        │   ├── 5.2.4.2 -- Ensemble methods\n",
      "        │   │   ├── 5.2.4.2.1 -- Boosting\n",
      "        │   │   ├── 5.2.4.2.2 -- Bagging\n",
      "        │   │   └── 5.2.4.2.3 -- Fusion of classifiers\n",
      "        │   ├── 5.2.4.3 -- Spectral methods\n",
      "        │   │   └── 5.2.4.3.1 -- Spectral clustering\n",
      "        │   ├── 5.2.4.4 -- Feature selection\n",
      "        │   └── 5.2.4.5 -- Regularization\n",
      "        │       └── 5.2.4.5.1 -- Generalized eigenvalue\n",
      "        └── 5.2.5 -- Cross-validation\n"
     ]
    }
   ],
   "source": [
    "save_taxonomy_txt(root_enh, 'visualization/taxonomies/taxonomy_vis_dfs_ENHANCED.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the taxonomy as a json dictionary\n",
    "from anytree.exporter import JsonExporter\n",
    "exporter = JsonExporter(indent=2)\n",
    "with open('input_data/taxonomies/taxonomy_dict.json', 'w') as f:\n",
    "    f.write(exporter.export(root))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
